{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique - Exercices tirés du MOOC d'Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données représente les chances de différents étudiants d'être admis à un programme universitaire en fonction de leurs résultats à deux examens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les données du fichier ex2data1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.6f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Herbology</th>\n",
       "      <th>Defense Against the Dark Arts</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Muggle Studies</th>\n",
       "      <th>Ancient Runes</th>\n",
       "      <th>History of Magic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.838620</td>\n",
       "      <td>1.141000</td>\n",
       "      <td>-0.408386</td>\n",
       "      <td>3.166563</td>\n",
       "      <td>-222.251269</td>\n",
       "      <td>495.700089</td>\n",
       "      <td>2.996567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>521.336774</td>\n",
       "      <td>5.227724</td>\n",
       "      <td>5.213368</td>\n",
       "      <td>4.167300</td>\n",
       "      <td>485.900919</td>\n",
       "      <td>106.652155</td>\n",
       "      <td>4.430561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-966.740546</td>\n",
       "      <td>-10.295663</td>\n",
       "      <td>-10.162119</td>\n",
       "      <td>-8.727000</td>\n",
       "      <td>-1043.961527</td>\n",
       "      <td>283.869609</td>\n",
       "      <td>-8.431117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-487.566992</td>\n",
       "      <td>-4.294050</td>\n",
       "      <td>-5.268236</td>\n",
       "      <td>3.085000</td>\n",
       "      <td>-573.969159</td>\n",
       "      <td>396.263595</td>\n",
       "      <td>2.238739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>261.844384</td>\n",
       "      <td>3.486307</td>\n",
       "      <td>-2.618444</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>-418.660994</td>\n",
       "      <td>463.918305</td>\n",
       "      <td>4.392980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>526.823552</td>\n",
       "      <td>5.428457</td>\n",
       "      <td>4.875670</td>\n",
       "      <td>5.730000</td>\n",
       "      <td>264.144523</td>\n",
       "      <td>598.104938</td>\n",
       "      <td>5.893868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1016.211940</td>\n",
       "      <td>10.296759</td>\n",
       "      <td>9.667405</td>\n",
       "      <td>10.032000</td>\n",
       "      <td>1092.388611</td>\n",
       "      <td>745.396220</td>\n",
       "      <td>11.889713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Astronomy    Herbology  Defense Against the Dark Arts   Divination  \\\n",
       "count  1363.000000  1363.000000                    1363.000000  1363.000000   \n",
       "mean     40.838620     1.141000                      -0.408386     3.166563   \n",
       "std     521.336774     5.227724                       5.213368     4.167300   \n",
       "min    -966.740546   -10.295663                     -10.162119    -8.727000   \n",
       "25%    -487.566992    -4.294050                      -5.268236     3.085000   \n",
       "50%     261.844384     3.486307                      -2.618444     4.625000   \n",
       "75%     526.823552     5.428457                       4.875670     5.730000   \n",
       "max    1016.211940    10.296759                       9.667405    10.032000   \n",
       "\n",
       "       Muggle Studies  Ancient Runes  History of Magic  \n",
       "count     1363.000000    1363.000000       1363.000000  \n",
       "mean      -222.251269     495.700089          2.996567  \n",
       "std        485.900919     106.652155          4.430561  \n",
       "min      -1043.961527     283.869609         -8.431117  \n",
       "25%       -573.969159     396.263595          2.238739  \n",
       "50%       -418.660994     463.918305          4.392980  \n",
       "75%        264.144523     598.104938          5.893868  \n",
       "max       1092.388611     745.396220         11.889713  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset_train.csv\")\n",
    "data = data.drop(columns = ['First Name', 'Last Name', 'Birthday', 'Best Hand', 'Index'])\n",
    "data = data.drop(columns = ['Arithmancy', 'Care of Magical Creatures']) #, 'Astronomy'])\n",
    "# data = data.drop(columns = ['Divination', 'Muggle Studies', 'History of Magic'])\n",
    "data = data.drop(columns = ['Flying', 'Potions', 'Charms', 'Transfiguration']) # ,'Transfiguration', , 'Ancient Runes'])\n",
    "\n",
    "\n",
    "data = data.dropna() #aulieu de dropna il faut fire la tang\n",
    "data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette semaine nous vous fournissons la visualisation des données, mais normalement vous auriez à produire un graphe semblable avec matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpez vos données en une matrice X et un vecteur y et transformerz-les en array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.column_stack((data['Herbology'] ,data['Defense Against the Dark Arts']))\n",
    "X = data.copy()\n",
    "X = X.drop(columns = ['Hogwarts House'])\n",
    "y = np.column_stack(data['Hogwarts House'])\n",
    "# X = np.c_[np.ones(X.shape[0]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Herbology</th>\n",
       "      <th>Defense Against the Dark Arts</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Muggle Studies</th>\n",
       "      <th>Ancient Runes</th>\n",
       "      <th>History of Magic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-487.886086</td>\n",
       "      <td>5.727180</td>\n",
       "      <td>4.878861</td>\n",
       "      <td>4.722</td>\n",
       "      <td>272.035831</td>\n",
       "      <td>532.484226</td>\n",
       "      <td>5.231058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-552.060507</td>\n",
       "      <td>-5.987446</td>\n",
       "      <td>5.520605</td>\n",
       "      <td>-5.612</td>\n",
       "      <td>-487.340557</td>\n",
       "      <td>367.760303</td>\n",
       "      <td>4.107170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-366.076117</td>\n",
       "      <td>7.725017</td>\n",
       "      <td>3.660761</td>\n",
       "      <td>6.140</td>\n",
       "      <td>664.893521</td>\n",
       "      <td>602.585284</td>\n",
       "      <td>3.555579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>697.742809</td>\n",
       "      <td>-6.497214</td>\n",
       "      <td>-6.977428</td>\n",
       "      <td>4.026</td>\n",
       "      <td>-537.001128</td>\n",
       "      <td>523.982133</td>\n",
       "      <td>-4.809637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-613.687160</td>\n",
       "      <td>-4.289197</td>\n",
       "      <td>6.136872</td>\n",
       "      <td>-6.592</td>\n",
       "      <td>-440.997704</td>\n",
       "      <td>396.201804</td>\n",
       "      <td>5.380286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>496.394945</td>\n",
       "      <td>-5.215891</td>\n",
       "      <td>-4.963949</td>\n",
       "      <td>5.855</td>\n",
       "      <td>-626.552041</td>\n",
       "      <td>567.842402</td>\n",
       "      <td>-6.198661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>527.193585</td>\n",
       "      <td>7.922205</td>\n",
       "      <td>-5.271936</td>\n",
       "      <td>3.356</td>\n",
       "      <td>-398.101991</td>\n",
       "      <td>341.475606</td>\n",
       "      <td>4.978614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>604.933962</td>\n",
       "      <td>5.484189</td>\n",
       "      <td>-6.049340</td>\n",
       "      <td>5.358</td>\n",
       "      <td>-530.795896</td>\n",
       "      <td>484.872671</td>\n",
       "      <td>5.699654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>438.556950</td>\n",
       "      <td>5.320518</td>\n",
       "      <td>-4.385569</td>\n",
       "      <td>3.014</td>\n",
       "      <td>-518.560718</td>\n",
       "      <td>417.064093</td>\n",
       "      <td>4.801437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>709.094614</td>\n",
       "      <td>1.705389</td>\n",
       "      <td>-7.090946</td>\n",
       "      <td>7.091</td>\n",
       "      <td>-328.712955</td>\n",
       "      <td>435.502183</td>\n",
       "      <td>6.300649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-544.192049</td>\n",
       "      <td>-7.308856</td>\n",
       "      <td>5.441920</td>\n",
       "      <td>-6.180</td>\n",
       "      <td>-319.946875</td>\n",
       "      <td>391.652916</td>\n",
       "      <td>2.914732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-197.527318</td>\n",
       "      <td>2.742444</td>\n",
       "      <td>1.975273</td>\n",
       "      <td>6.603</td>\n",
       "      <td>527.356323</td>\n",
       "      <td>605.590600</td>\n",
       "      <td>5.480097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-447.649812</td>\n",
       "      <td>4.046727</td>\n",
       "      <td>4.476498</td>\n",
       "      <td>4.949</td>\n",
       "      <td>810.154483</td>\n",
       "      <td>615.531088</td>\n",
       "      <td>3.653495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>470.653757</td>\n",
       "      <td>-5.518264</td>\n",
       "      <td>-4.706538</td>\n",
       "      <td>4.425</td>\n",
       "      <td>-434.293266</td>\n",
       "      <td>596.610089</td>\n",
       "      <td>-4.161823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>651.198749</td>\n",
       "      <td>-4.820771</td>\n",
       "      <td>-6.511987</td>\n",
       "      <td>4.357</td>\n",
       "      <td>-468.284723</td>\n",
       "      <td>626.372886</td>\n",
       "      <td>-5.206672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-151.088209</td>\n",
       "      <td>6.871857</td>\n",
       "      <td>1.510882</td>\n",
       "      <td>7.906</td>\n",
       "      <td>645.447451</td>\n",
       "      <td>607.442729</td>\n",
       "      <td>6.317446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>458.127026</td>\n",
       "      <td>6.981589</td>\n",
       "      <td>-4.581270</td>\n",
       "      <td>5.686</td>\n",
       "      <td>-579.668591</td>\n",
       "      <td>403.327690</td>\n",
       "      <td>4.265810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>703.553548</td>\n",
       "      <td>-3.858216</td>\n",
       "      <td>-7.035535</td>\n",
       "      <td>5.866</td>\n",
       "      <td>-433.250359</td>\n",
       "      <td>610.732670</td>\n",
       "      <td>-5.029523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-264.678311</td>\n",
       "      <td>5.949951</td>\n",
       "      <td>2.646783</td>\n",
       "      <td>6.829</td>\n",
       "      <td>745.465666</td>\n",
       "      <td>626.823332</td>\n",
       "      <td>4.886733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>673.167110</td>\n",
       "      <td>0.131516</td>\n",
       "      <td>-6.731671</td>\n",
       "      <td>9.421</td>\n",
       "      <td>-709.696428</td>\n",
       "      <td>461.896734</td>\n",
       "      <td>0.531823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-511.226438</td>\n",
       "      <td>7.963184</td>\n",
       "      <td>5.112264</td>\n",
       "      <td>5.769</td>\n",
       "      <td>419.755599</td>\n",
       "      <td>663.157592</td>\n",
       "      <td>7.089608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>508.161188</td>\n",
       "      <td>6.113144</td>\n",
       "      <td>-5.081612</td>\n",
       "      <td>3.284</td>\n",
       "      <td>-387.555981</td>\n",
       "      <td>407.319941</td>\n",
       "      <td>5.142065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-419.022085</td>\n",
       "      <td>-6.655230</td>\n",
       "      <td>4.190221</td>\n",
       "      <td>-6.006</td>\n",
       "      <td>-322.019869</td>\n",
       "      <td>408.628000</td>\n",
       "      <td>4.837897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>612.593032</td>\n",
       "      <td>4.166335</td>\n",
       "      <td>-6.125930</td>\n",
       "      <td>5.142</td>\n",
       "      <td>-528.809527</td>\n",
       "      <td>455.114741</td>\n",
       "      <td>1.879998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>236.888879</td>\n",
       "      <td>-5.077751</td>\n",
       "      <td>-2.368889</td>\n",
       "      <td>5.517</td>\n",
       "      <td>-544.758909</td>\n",
       "      <td>604.096378</td>\n",
       "      <td>-4.955320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>458.342038</td>\n",
       "      <td>3.331786</td>\n",
       "      <td>-4.583420</td>\n",
       "      <td>5.794</td>\n",
       "      <td>-357.144381</td>\n",
       "      <td>327.384627</td>\n",
       "      <td>8.575962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>600.081350</td>\n",
       "      <td>3.464527</td>\n",
       "      <td>-6.000813</td>\n",
       "      <td>6.881</td>\n",
       "      <td>-678.523644</td>\n",
       "      <td>387.235626</td>\n",
       "      <td>5.687413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>514.341937</td>\n",
       "      <td>-2.832055</td>\n",
       "      <td>-5.143419</td>\n",
       "      <td>5.754</td>\n",
       "      <td>-685.171030</td>\n",
       "      <td>618.441409</td>\n",
       "      <td>-7.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-301.483373</td>\n",
       "      <td>4.470596</td>\n",
       "      <td>3.014834</td>\n",
       "      <td>6.545</td>\n",
       "      <td>887.027852</td>\n",
       "      <td>650.595404</td>\n",
       "      <td>5.728552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>413.574984</td>\n",
       "      <td>4.907537</td>\n",
       "      <td>-4.135750</td>\n",
       "      <td>3.259</td>\n",
       "      <td>-363.096593</td>\n",
       "      <td>325.814384</td>\n",
       "      <td>4.604073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>-338.473744</td>\n",
       "      <td>3.083534</td>\n",
       "      <td>3.384737</td>\n",
       "      <td>6.022</td>\n",
       "      <td>338.258898</td>\n",
       "      <td>619.806989</td>\n",
       "      <td>5.684107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>723.816839</td>\n",
       "      <td>-6.016943</td>\n",
       "      <td>-7.238168</td>\n",
       "      <td>3.719</td>\n",
       "      <td>-504.858621</td>\n",
       "      <td>595.501832</td>\n",
       "      <td>-2.956451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>-604.360936</td>\n",
       "      <td>5.705587</td>\n",
       "      <td>6.043609</td>\n",
       "      <td>3.817</td>\n",
       "      <td>164.809168</td>\n",
       "      <td>569.870545</td>\n",
       "      <td>6.380305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>-637.568578</td>\n",
       "      <td>6.310939</td>\n",
       "      <td>6.375686</td>\n",
       "      <td>4.571</td>\n",
       "      <td>615.638520</td>\n",
       "      <td>623.105908</td>\n",
       "      <td>3.883735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>-567.084523</td>\n",
       "      <td>-4.789794</td>\n",
       "      <td>5.670845</td>\n",
       "      <td>-5.053</td>\n",
       "      <td>-253.721474</td>\n",
       "      <td>441.092731</td>\n",
       "      <td>4.720936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>436.565134</td>\n",
       "      <td>2.248675</td>\n",
       "      <td>-4.365651</td>\n",
       "      <td>5.779</td>\n",
       "      <td>-599.867721</td>\n",
       "      <td>376.959288</td>\n",
       "      <td>3.055896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>324.973343</td>\n",
       "      <td>-9.142445</td>\n",
       "      <td>-3.249733</td>\n",
       "      <td>2.001</td>\n",
       "      <td>-639.356779</td>\n",
       "      <td>540.345734</td>\n",
       "      <td>-4.498216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>-731.834952</td>\n",
       "      <td>6.362544</td>\n",
       "      <td>7.318350</td>\n",
       "      <td>4.151</td>\n",
       "      <td>338.088711</td>\n",
       "      <td>585.956497</td>\n",
       "      <td>2.640869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>-384.405691</td>\n",
       "      <td>2.282681</td>\n",
       "      <td>3.844057</td>\n",
       "      <td>5.774</td>\n",
       "      <td>567.490358</td>\n",
       "      <td>639.915066</td>\n",
       "      <td>6.305970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>-626.623309</td>\n",
       "      <td>3.117287</td>\n",
       "      <td>6.266233</td>\n",
       "      <td>5.025</td>\n",
       "      <td>778.083678</td>\n",
       "      <td>625.241315</td>\n",
       "      <td>5.777496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>419.360183</td>\n",
       "      <td>-6.242092</td>\n",
       "      <td>-4.193602</td>\n",
       "      <td>3.989</td>\n",
       "      <td>-310.695714</td>\n",
       "      <td>620.726433</td>\n",
       "      <td>-3.644746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>-243.223485</td>\n",
       "      <td>-3.234020</td>\n",
       "      <td>2.432235</td>\n",
       "      <td>-5.750</td>\n",
       "      <td>-195.945722</td>\n",
       "      <td>488.030049</td>\n",
       "      <td>1.099770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>-656.740586</td>\n",
       "      <td>-5.019345</td>\n",
       "      <td>6.567406</td>\n",
       "      <td>-5.950</td>\n",
       "      <td>-638.746529</td>\n",
       "      <td>353.912068</td>\n",
       "      <td>5.430560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>-763.407257</td>\n",
       "      <td>6.297962</td>\n",
       "      <td>7.634073</td>\n",
       "      <td>2.706</td>\n",
       "      <td>610.741872</td>\n",
       "      <td>579.790276</td>\n",
       "      <td>5.949461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>-575.789160</td>\n",
       "      <td>-1.841579</td>\n",
       "      <td>5.757892</td>\n",
       "      <td>-3.098</td>\n",
       "      <td>-551.554687</td>\n",
       "      <td>416.352506</td>\n",
       "      <td>3.908679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>-347.982861</td>\n",
       "      <td>-4.492272</td>\n",
       "      <td>3.479829</td>\n",
       "      <td>-6.947</td>\n",
       "      <td>-144.656302</td>\n",
       "      <td>465.318171</td>\n",
       "      <td>2.913881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>472.346537</td>\n",
       "      <td>6.791648</td>\n",
       "      <td>-4.723465</td>\n",
       "      <td>4.852</td>\n",
       "      <td>-726.054080</td>\n",
       "      <td>406.088500</td>\n",
       "      <td>-0.611872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>-485.249736</td>\n",
       "      <td>-8.390447</td>\n",
       "      <td>4.852497</td>\n",
       "      <td>-6.040</td>\n",
       "      <td>-522.882041</td>\n",
       "      <td>370.798886</td>\n",
       "      <td>6.622655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>511.749312</td>\n",
       "      <td>4.930942</td>\n",
       "      <td>-5.117493</td>\n",
       "      <td>4.114</td>\n",
       "      <td>-533.539229</td>\n",
       "      <td>406.699691</td>\n",
       "      <td>4.331819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>708.202206</td>\n",
       "      <td>4.850931</td>\n",
       "      <td>-7.082022</td>\n",
       "      <td>5.660</td>\n",
       "      <td>-504.777873</td>\n",
       "      <td>417.520448</td>\n",
       "      <td>4.568628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>-569.513380</td>\n",
       "      <td>6.915328</td>\n",
       "      <td>5.695134</td>\n",
       "      <td>3.958</td>\n",
       "      <td>559.775978</td>\n",
       "      <td>543.431180</td>\n",
       "      <td>2.882075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>-507.715746</td>\n",
       "      <td>-4.997610</td>\n",
       "      <td>5.077157</td>\n",
       "      <td>-5.637</td>\n",
       "      <td>-443.781855</td>\n",
       "      <td>386.058513</td>\n",
       "      <td>6.990603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>376.920722</td>\n",
       "      <td>-2.949527</td>\n",
       "      <td>-3.769207</td>\n",
       "      <td>7.311</td>\n",
       "      <td>-416.672294</td>\n",
       "      <td>624.056215</td>\n",
       "      <td>-6.638366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>-426.175401</td>\n",
       "      <td>5.681107</td>\n",
       "      <td>4.261754</td>\n",
       "      <td>6.205</td>\n",
       "      <td>473.879478</td>\n",
       "      <td>647.238809</td>\n",
       "      <td>6.254227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>599.901612</td>\n",
       "      <td>5.479485</td>\n",
       "      <td>-5.999016</td>\n",
       "      <td>5.543</td>\n",
       "      <td>-525.883264</td>\n",
       "      <td>467.950418</td>\n",
       "      <td>5.933211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>354.280086</td>\n",
       "      <td>-4.541837</td>\n",
       "      <td>-3.542801</td>\n",
       "      <td>5.702</td>\n",
       "      <td>-497.235066</td>\n",
       "      <td>618.220213</td>\n",
       "      <td>-5.231721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>367.531174</td>\n",
       "      <td>6.061064</td>\n",
       "      <td>-3.675312</td>\n",
       "      <td>1.757</td>\n",
       "      <td>-643.271092</td>\n",
       "      <td>445.827565</td>\n",
       "      <td>2.238112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>544.018925</td>\n",
       "      <td>-3.203269</td>\n",
       "      <td>-5.440189</td>\n",
       "      <td>6.065</td>\n",
       "      <td>-385.150457</td>\n",
       "      <td>635.211486</td>\n",
       "      <td>-5.984257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>453.676219</td>\n",
       "      <td>3.442831</td>\n",
       "      <td>-4.536762</td>\n",
       "      <td>6.738</td>\n",
       "      <td>-831.741123</td>\n",
       "      <td>383.444937</td>\n",
       "      <td>3.813111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>688.911989</td>\n",
       "      <td>5.421046</td>\n",
       "      <td>-6.889120</td>\n",
       "      <td>6.593</td>\n",
       "      <td>-234.207911</td>\n",
       "      <td>339.775154</td>\n",
       "      <td>7.208415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1363 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Astronomy  Herbology  Defense Against the Dark Arts  Divination  \\\n",
       "0    -487.886086   5.727180                       4.878861       4.722   \n",
       "1    -552.060507  -5.987446                       5.520605      -5.612   \n",
       "2    -366.076117   7.725017                       3.660761       6.140   \n",
       "3     697.742809  -6.497214                      -6.977428       4.026   \n",
       "5    -613.687160  -4.289197                       6.136872      -6.592   \n",
       "8     496.394945  -5.215891                      -4.963949       5.855   \n",
       "9     527.193585   7.922205                      -5.271936       3.356   \n",
       "10    604.933962   5.484189                      -6.049340       5.358   \n",
       "11    438.556950   5.320518                      -4.385569       3.014   \n",
       "12    709.094614   1.705389                      -7.090946       7.091   \n",
       "13   -544.192049  -7.308856                       5.441920      -6.180   \n",
       "14   -197.527318   2.742444                       1.975273       6.603   \n",
       "15   -447.649812   4.046727                       4.476498       4.949   \n",
       "16    470.653757  -5.518264                      -4.706538       4.425   \n",
       "17    651.198749  -4.820771                      -6.511987       4.357   \n",
       "18   -151.088209   6.871857                       1.510882       7.906   \n",
       "19    458.127026   6.981589                      -4.581270       5.686   \n",
       "20    703.553548  -3.858216                      -7.035535       5.866   \n",
       "22   -264.678311   5.949951                       2.646783       6.829   \n",
       "23    673.167110   0.131516                      -6.731671       9.421   \n",
       "24   -511.226438   7.963184                       5.112264       5.769   \n",
       "25    508.161188   6.113144                      -5.081612       3.284   \n",
       "26   -419.022085  -6.655230                       4.190221      -6.006   \n",
       "27    612.593032   4.166335                      -6.125930       5.142   \n",
       "28    236.888879  -5.077751                      -2.368889       5.517   \n",
       "29    458.342038   3.331786                      -4.583420       5.794   \n",
       "30    600.081350   3.464527                      -6.000813       6.881   \n",
       "31    514.341937  -2.832055                      -5.143419       5.754   \n",
       "32   -301.483373   4.470596                       3.014834       6.545   \n",
       "33    413.574984   4.907537                      -4.135750       3.259   \n",
       "...          ...        ...                            ...         ...   \n",
       "1564 -338.473744   3.083534                       3.384737       6.022   \n",
       "1566  723.816839  -6.016943                      -7.238168       3.719   \n",
       "1567 -604.360936   5.705587                       6.043609       3.817   \n",
       "1568 -637.568578   6.310939                       6.375686       4.571   \n",
       "1571 -567.084523  -4.789794                       5.670845      -5.053   \n",
       "1572  436.565134   2.248675                      -4.365651       5.779   \n",
       "1573  324.973343  -9.142445                      -3.249733       2.001   \n",
       "1574 -731.834952   6.362544                       7.318350       4.151   \n",
       "1576 -384.405691   2.282681                       3.844057       5.774   \n",
       "1577 -626.623309   3.117287                       6.266233       5.025   \n",
       "1578  419.360183  -6.242092                      -4.193602       3.989   \n",
       "1579 -243.223485  -3.234020                       2.432235      -5.750   \n",
       "1581 -656.740586  -5.019345                       6.567406      -5.950   \n",
       "1582 -763.407257   6.297962                       7.634073       2.706   \n",
       "1583 -575.789160  -1.841579                       5.757892      -3.098   \n",
       "1584 -347.982861  -4.492272                       3.479829      -6.947   \n",
       "1585  472.346537   6.791648                      -4.723465       4.852   \n",
       "1586 -485.249736  -8.390447                       4.852497      -6.040   \n",
       "1587  511.749312   4.930942                      -5.117493       4.114   \n",
       "1589  708.202206   4.850931                      -7.082022       5.660   \n",
       "1590 -569.513380   6.915328                       5.695134       3.958   \n",
       "1591 -507.715746  -4.997610                       5.077157      -5.637   \n",
       "1592  376.920722  -2.949527                      -3.769207       7.311   \n",
       "1593 -426.175401   5.681107                       4.261754       6.205   \n",
       "1594  599.901612   5.479485                      -5.999016       5.543   \n",
       "1595  354.280086  -4.541837                      -3.542801       5.702   \n",
       "1596  367.531174   6.061064                      -3.675312       1.757   \n",
       "1597  544.018925  -3.203269                      -5.440189       6.065   \n",
       "1598  453.676219   3.442831                      -4.536762       6.738   \n",
       "1599  688.911989   5.421046                      -6.889120       6.593   \n",
       "\n",
       "      Muggle Studies  Ancient Runes  History of Magic  \n",
       "0         272.035831     532.484226          5.231058  \n",
       "1        -487.340557     367.760303          4.107170  \n",
       "2         664.893521     602.585284          3.555579  \n",
       "3        -537.001128     523.982133         -4.809637  \n",
       "5        -440.997704     396.201804          5.380286  \n",
       "8        -626.552041     567.842402         -6.198661  \n",
       "9        -398.101991     341.475606          4.978614  \n",
       "10       -530.795896     484.872671          5.699654  \n",
       "11       -518.560718     417.064093          4.801437  \n",
       "12       -328.712955     435.502183          6.300649  \n",
       "13       -319.946875     391.652916          2.914732  \n",
       "14        527.356323     605.590600          5.480097  \n",
       "15        810.154483     615.531088          3.653495  \n",
       "16       -434.293266     596.610089         -4.161823  \n",
       "17       -468.284723     626.372886         -5.206672  \n",
       "18        645.447451     607.442729          6.317446  \n",
       "19       -579.668591     403.327690          4.265810  \n",
       "20       -433.250359     610.732670         -5.029523  \n",
       "22        745.465666     626.823332          4.886733  \n",
       "23       -709.696428     461.896734          0.531823  \n",
       "24        419.755599     663.157592          7.089608  \n",
       "25       -387.555981     407.319941          5.142065  \n",
       "26       -322.019869     408.628000          4.837897  \n",
       "27       -528.809527     455.114741          1.879998  \n",
       "28       -544.758909     604.096378         -4.955320  \n",
       "29       -357.144381     327.384627          8.575962  \n",
       "30       -678.523644     387.235626          5.687413  \n",
       "31       -685.171030     618.441409         -7.003953  \n",
       "32        887.027852     650.595404          5.728552  \n",
       "33       -363.096593     325.814384          4.604073  \n",
       "...              ...            ...               ...  \n",
       "1564      338.258898     619.806989          5.684107  \n",
       "1566     -504.858621     595.501832         -2.956451  \n",
       "1567      164.809168     569.870545          6.380305  \n",
       "1568      615.638520     623.105908          3.883735  \n",
       "1571     -253.721474     441.092731          4.720936  \n",
       "1572     -599.867721     376.959288          3.055896  \n",
       "1573     -639.356779     540.345734         -4.498216  \n",
       "1574      338.088711     585.956497          2.640869  \n",
       "1576      567.490358     639.915066          6.305970  \n",
       "1577      778.083678     625.241315          5.777496  \n",
       "1578     -310.695714     620.726433         -3.644746  \n",
       "1579     -195.945722     488.030049          1.099770  \n",
       "1581     -638.746529     353.912068          5.430560  \n",
       "1582      610.741872     579.790276          5.949461  \n",
       "1583     -551.554687     416.352506          3.908679  \n",
       "1584     -144.656302     465.318171          2.913881  \n",
       "1585     -726.054080     406.088500         -0.611872  \n",
       "1586     -522.882041     370.798886          6.622655  \n",
       "1587     -533.539229     406.699691          4.331819  \n",
       "1589     -504.777873     417.520448          4.568628  \n",
       "1590      559.775978     543.431180          2.882075  \n",
       "1591     -443.781855     386.058513          6.990603  \n",
       "1592     -416.672294     624.056215         -6.638366  \n",
       "1593      473.879478     647.238809          6.254227  \n",
       "1594     -525.883264     467.950418          5.933211  \n",
       "1595     -497.235066     618.220213         -5.231721  \n",
       "1596     -643.271092     445.827565          2.238112  \n",
       "1597     -385.150457     635.211486         -5.984257  \n",
       "1598     -831.741123     383.444937          3.813111  \n",
       "1599     -234.207911     339.775154          7.208415  \n",
       "\n",
       "[1363 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000, -1.014543, 0.877603, ..., 1.017632, 0.345025, 0.504521],\n",
       "       [1.000000, -1.137684, -1.364085, ..., -0.545763, -1.200039,\n",
       "        0.250761],\n",
       "       [1.000000, -0.780808, 1.259905, ..., 1.826443, 1.002553, 0.126218],\n",
       "       ...,\n",
       "       [1.000000, 0.965527, -0.831311, ..., -0.335375, 1.308577,\n",
       "        -2.027761],\n",
       "       [1.000000, 0.792173, 0.440474, ..., -1.254810, -1.052922,\n",
       "        0.184366],\n",
       "       [1.000000, 1.243556, 0.819021, ..., -0.024616, -1.462532,\n",
       "        0.950984]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalise(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "X = normalise(X)\n",
    "X = np.c_[np.ones(X.shape[0]), X]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Ravenclaw', 'Slytherin', 'Ravenclaw', ..., 'Gryffindor',\n",
       "        'Hufflepuff', 'Hufflepuff']], dtype='<U10')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_Ravenclaw = y == \"Ravenclaw\"\n",
    "mask_Gryffindor = y == \"Gryffindor\"\n",
    "mask_Hufflepuff = y == \"Hufflepuff\"\n",
    "mask_Slytherin = y == \"Slytherin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_Ravenclaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez bien les dimensions de vos structures de données (X.shape)  \n",
    "Rappelez-vous qu'il est judicieux de fixer les dimensions des vecteurs, par ex. (3,) avec la fonction reshape(3,1).\n",
    "La matrice X doit-elle être de dimensions m x n ou bien m x (n+1) ? Quelle est la valeur de n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisez theta en un vecteur de zéros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Combien de zéros vous faudra-t-il....?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Formulation de l'hypothèse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revoyez l'équation de l'hypothèse de la régression logistique. Le produit de theta et de X est enveloppé dans une fonction g(z) qui correspond à la fonction sigmoïde. Nous allons commencer par coder cette fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Écrivez une fonction _sigmoid_ qui applique la sigmoïde à son argument et retourne le résultat. Si elle reçoit une matrice ou un vecteur en input, elle doit s'appliquer sur chaque élément individuellement et retourner une structure de mêmes dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    #print (np.exp(-z))\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez votre fonction. Quelle valeur renvoie une sigmoïde si z=0? Si z est grand? Si z est petit?  \n",
    "Il est possible que vous ayez un bug lorsque la fonction exponentielle reçoit des valeurs trop grandes. Dans ce cas vous pourrez éventuellement remplacer votre fonction sigmoïde par celle de scipy pour éviter des problèmes dans le reste de votre implémentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Écrivez une fonction _predict_, qui correspond à l'hypohèse hθ(x), qui prend en paramètres X et theta, applique l'hypothèse du modèle avec la fonction sigmoide, et se débrouille pour que le résultat final soit un vecteur de 1 et de 0 correspondant aux catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    #print(X.shape, theta.shape)\n",
    "    res = sigmoid(np.dot(X, theta.T))\n",
    "    #print(res.shape)\n",
    "    #print(res)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Définissez la fonction de coût de votre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, theta):\n",
    "    return((-1 / X.shape[0]) * np.sum(y * np.log(predict(X, theta)) + (1 - y) * np.log(1 - predict(X, theta))))\n",
    "\n",
    "#((-1 / X.shape[0])\n",
    "#pensser a normaliser les donées en premier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculez le coût de votre modèle non entraîné. Vous devriez obtenir une valeur d'environ 0.693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599454\n"
     ]
    }
   ],
   "source": [
    "theta = np.zeros(X.shape[1], dtype=float)\n",
    "print (cost(X, mask_Ravenclaw, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Écrivez une fonction _fit_ qui prend en arguments le vecteur X et le vecteur y des données d'entraînement et renvoie le vecteur de paramètres _theta_ qui a été appris, ainsi que l'évolution du coût"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter que l'exercice original ne fait pas faire la descente du gradient pour entraîner le modèle, mais plutôt une fonction d'optimisation avancée (_fminunc_ en Matlab). Nous tenterons de faire quand même la descente du gradient. Les plus téméraires peuvent aussi trouver une fonction d'optimisation équivalente en Python et comparer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(X, y, theta, alpha, num_iters):\n",
    "#     # Initialiser certaines variables utiles\n",
    "#     m = X.shape[0]\n",
    "#     print (m)\n",
    "#     J_history = []\n",
    "#     for _ in range(num_iters):\n",
    "#         theta = theta - (alpha / m) * (np.dot(predict(X, theta) - y, X))\n",
    "#         #print(theta)\n",
    "#         J_history.append(cost(X, y, theta))\n",
    "#     return theta, J_history\n",
    "\n",
    "def fit(X, y, theta, alpha, num_iters):\n",
    "    # Initialiser certaines variables utiles\n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "    for _ in tqdm(range(num_iters)):\n",
    "        theta = theta - (alpha / m) * (np.dot(predict(X, theta) - y, X))\n",
    "        J_history.append(cost(X, y, theta))\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancez l'apprentissage en appelant la fonction _fit_ et en prenant bien soin de récupérer le résultat de *theta* à la fin!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyez entre vous quelles valeurs semblent correctes pour alpha et num_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:09<00:00,  5.32it/s]\n",
      "100%|██████████| 500/500 [01:24<00:00,  3.95it/s]\n",
      "100%|██████████| 500/500 [01:24<00:00,  7.86it/s]\n",
      "100%|██████████| 500/500 [01:15<00:00,  9.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# theta = np.zeros(3, dtype=float)\n",
    "# print (X.shape, theta.shape, y.shape)\n",
    "\n",
    "\n",
    "# theta = np.zeros(X.shape[1], dtype=float)\n",
    "# thetaR, J_historyR = fit(X, mask_Ravenclaw, theta, 0.001, 600)\n",
    "# theta = np.zeros(X.shape[1], dtype=float)\n",
    "# thetaG, J_historyG = fit(X, mask_Gryffindor, theta, 0.001, 1100)\n",
    "# theta = np.zeros(X.shape[1], dtype=float)\n",
    "# thetaH, J_historyH = fit(X, mask_Hufflepuff, theta, 0.001, 200)\n",
    "# theta = np.zeros(X.shape[1], dtype=float)\n",
    "# thetaS, J_historyS = fit(X, mask_Slytherin, theta, 0.001, 1200)\n",
    "\n",
    "theta = np.zeros(X.shape[1], dtype=float)\n",
    "thetaR, J_historyR = fit(X, mask_Ravenclaw, theta, 0.0001, 500)\n",
    "theta = np.zeros(X.shape[1], dtype=float)\n",
    "thetaG, J_historyG = fit(X, mask_Gryffindor, theta, 0.0001, 500)\n",
    "theta = np.zeros(X.shape[1], dtype=float)\n",
    "thetaH, J_historyH = fit(X, mask_Hufflepuff, theta, 0.0001, 500)\n",
    "theta = np.zeros(X.shape[1], dtype=float)\n",
    "thetaS, J_historyS = fit(X, mask_Slytherin, theta, 0.0001, 500)\n",
    "\n",
    "\n",
    "# print (thetaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appelez la fonction _cost_ avec le nouveau theta après entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez obtenir une valeur autour de 0.203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost(X, mask_Ravenclaw, theta)\n",
    "thetas = np.array([thetaG[X.shape[0]-1], thetaS[X.shape[0]-1], thetaH[X.shape[0]-1], thetaR[X.shape[0]-1]])\n",
    "np.savetxt('thetas.csv', thetas, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On visualise maintenant l'évolution du coût en fonction du nombre d'itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121527630>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_historyR)\n",
    "ax.plot(J_historyG)\n",
    "ax.plot(J_historyH)\n",
    "ax.plot(J_historyS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation de votre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons évaluer la performance du modèle de deux façons:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluez la probabilité qu'un étudiant ayant obtenu 45 au premier examen, et 85 au deuxième, soit admis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez avoir une probabilité d'admission de 0.776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluer l'exactitude (accuracy) des prédictions faites sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez votre fonction _predict_ sur les données d'entraînement (X) et récupérez les prédictions dans un vecteur p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"dataset_test.csv\")\n",
    "\n",
    "solution = pd.read_csv(\"Correction/dataset_truth.csv\")\n",
    "\n",
    "# solution = np.column_stack((solution['Herbology'] ,solution['Defense Against the Dark Arts']))\n",
    "\n",
    "test = test.drop(columns = ['Hogwarts House'])\n",
    "\n",
    "test = test.drop(columns = ['First Name', 'Last Name', 'Birthday', 'Best Hand', 'Index'])\n",
    "test = test.drop(columns = ['Arithmancy', 'Care of Magical Creatures', 'Astronomy'])\n",
    "\n",
    "test.describe()\n",
    "\n",
    "# toto = np.column_stack((test['Herbology'] ,test['Defense Against the Dark Arts']))\n",
    "# toto = np.column_stack((toto ,test['Ancient Runes']))\n",
    "\n",
    "\n",
    "# test = test.dropna() #aulieu de dropna il faut fire la tang\n",
    "\n",
    "# a = 0\n",
    "# while a < toto.shape[0]:\n",
    "#     if np.isnan(toto[a][0]):\n",
    "# #         print (test[a][0])\n",
    "#         toto[a][0] = 5.055295\n",
    "# #         print (test[a][0])\n",
    "#     if np.isnan(toto[a][1]):\n",
    "# #         print (test[a][1])\n",
    "#         toto[a][1] = 5.118762\n",
    "# #         print (test[a][1])\n",
    "#     if np.isnan(toto[a][1]):\n",
    "# #         print (test[a][1])\n",
    "#         toto[a][2] = 101.657418\n",
    "#     a += 1\n",
    "\n",
    "    \n",
    "# a = 0\n",
    "# b = 0\n",
    "# while a < test.shape[0]:\n",
    "#     b = 0\n",
    "#     while b < 11:\n",
    "#         if np.isnan(test[a][b]):\n",
    "#             test[a][b] = 0\n",
    "#             b += 1\n",
    "#     a += 1\n",
    "    \n",
    "# toto = np.c_[np.ones(toto.shape[0]), toto]\n",
    "\n",
    "test = normalise(test)\n",
    "test = np.c_[np.ones(test.shape[0]), test]\n",
    "\n",
    "# toto\n",
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = predict(test, thetaR)\n",
    "G = predict(test, thetaG)\n",
    "S = predict(test, thetaS)\n",
    "H = predict(test, thetaH)\n",
    "\n",
    "print ('Ravenclaw =', R, '\\nGryffindor = ', G, '\\nSlytherin =' , S, '\\nHufflepuff =' ,H)\n",
    "print (solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array([[\"Index\", \"Hogwarts House\"]])\n",
    "for i in range(len(R)):\n",
    "    is_r = True if R[i] >= G[i] and R[i] >= S[i] and R[i] >= H[i] else False\n",
    "    is_g = True if G[i] >= R[i] and G[i] >= S[i] and G[i] >= H[i] else False\n",
    "    is_s = True if S[i] >= R[i] and S[i] >= G[i] and S[i] >= H[i] else False\n",
    "    is_h = True if H[i] >= R[i] and H[i] >= G[i] and H[i] >= S[i] else False\n",
    "\n",
    "    if is_r :\n",
    "        house = \"Ravenclaw\"\n",
    "    elif is_g :\n",
    "        house = \"Gryffindor\"\n",
    "    elif is_s :\n",
    "        house = \"Slytherin\"\n",
    "    else :\n",
    "        house = \"Hufflepuff\"\n",
    "    result = np.append (result, [[ids[i], house]], axis = 0)\n",
    "\n",
    "np.savetxt('houses.csv', result, delimiter=',', fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez le pourcentage des éléments de p qui correspondent à ceux de y. Ça vous donne le score d'exactitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 0\n",
    "total = 0\n",
    "for tmp, ground_truth in zip(X, y):\n",
    "    result = round(predict(tmp, theta))\n",
    "    if result == ground_truth:\n",
    "        precision += 1\n",
    "    total += 1\n",
    "print((precision / total) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez avoir un score d'environ 89.0 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelle est la précision, le recall et le F1-score de votre modele ? (écrivez trois fonctions pour obtenir chacunes de ces métriques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(X, y, theta):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    for tmp, ground_truth in zip(X, y):\n",
    "        result = round(predict(tmp, theta))\n",
    "        if result == 1 and ground_truth == 1:\n",
    "            true_pos += 1\n",
    "        elif result == 1 and ground_truth == 0:\n",
    "            false_pos += 1\n",
    "    return((true_pos / (true_pos + false_pos + 0.001)) * 100)\n",
    "    \n",
    "def recall(X, y, theta):\n",
    "    true_pos = 0\n",
    "    false_neg = 0\n",
    "    for tmp, ground_truth in zip(X, y):\n",
    "        result = round(predict(tmp, theta))\n",
    "        if result == 1 and ground_truth == 1:\n",
    "            true_pos += 1\n",
    "        elif result == 0 and ground_truth == 1:\n",
    "            false_neg += 1\n",
    "    return((true_pos / (true_pos + false_neg + 0.001)) * 100)\n",
    "\n",
    "def f1_score(X, y, theta):\n",
    "    prec = precision(X, y, theta)\n",
    "    rec = recall(X, y, theta)\n",
    "    return (2 * ((prec * rec) / (prec + rec + 0.001)))\n",
    "\n",
    "print(\"precision : {}\".format(precision(X, y, theta)))\n",
    "print(\"recall : {}\".format(recall(X, y, theta)))\n",
    "print(\"f1_score : {}\".format(f1_score(X, y, theta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A l'aide de l'hyperparameter tuning (random search), trouvez les alpha et lambda qui permettent de maximiser le F1-score. Vous devrez entrainer plusieurs fois votre modele à l'aide de la fonction fit pour trouver ces parametres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a9ad3bb73e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mf1_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0ma_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-a9ad3bb73e45>\u001b[0m in \u001b[0;36mrandom_search\u001b[0;34m(occurences, iters, alpha_range)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtmp_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0ma_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mf1_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-0b4a28cfdedf>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(X, y, theta, alpha, num_iters)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mJ_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mJ_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "alpha_range = [0.001, 0.002]\n",
    "def random_search(occurences=50,\n",
    "                  iters=1000,\n",
    "                  alpha_range = [0.001, 0.002]\n",
    "                  ):\n",
    "    a_history = []\n",
    "    f1_history = []\n",
    "    for _ in range(occurences):\n",
    "        tmp_alpha = np.random.uniform(alpha_range[0],alpha_range[1])\n",
    "        theta = np.zeros(X.shape[1])\n",
    "        theta, J_history = fit(X, y, theta, tmp_alpha, iters)\n",
    "        a_history.append(tmp_alpha)\n",
    "        f1_history.append(f1_score(X, y, theta))\n",
    "    return (a_history, f1_history)\n",
    "a_history, f1_history = random_search(alpha_range=alpha_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(f1_history, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_10_index = list(np.argsort(f1_history[1])[-10:])\n",
    "min_a = 1.0\n",
    "max_a = 0.0\n",
    "for elem in max_10_index:\n",
    "    a = a_history[elem]\n",
    "    if a > max_a:\n",
    "        max_a = a\n",
    "    if a < min_a:\n",
    "        min_a = a\n",
    "alpha_range = [min_a, max_a]\n",
    "alpha_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Visualisez la frontière de décision (decision boundary) sur le graphe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ceux qui veulent découvrir Matplotlib, il faut ici afficher les données en deux nuages de points distincts (pour les deux classes) sur le même graphe, et aussi trouver une façon de tracer la fonction qui définit la frontière de décision. Amusez-vous bien, et surtout aidez-vous! Voici un exemple de ce que ça devrait donner:  \n",
    "<img src=\"figure-2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intercept_slope(theta):\n",
    "    x_1 = 0\n",
    "    intercept = 0\n",
    "    pred = 0\n",
    "    while pred < 0.5:\n",
    "        p = [1, x_1, intercept]\n",
    "        intercept += 0.1\n",
    "        pred = predict(p, theta)\n",
    "    x_1 = 30\n",
    "    x_2 = 40\n",
    "    y_1 = 0\n",
    "    y_2 = 0\n",
    "    pred = 0\n",
    "    while pred < 0.5:\n",
    "        p = [1, x_1, y_1]\n",
    "        y_1 += 0.1\n",
    "        pred = predict(p, theta)\n",
    "    pred = 0\n",
    "    while pred < 0.5:\n",
    "        p = [1, x_2, y_2]\n",
    "        y_2 += 0.1\n",
    "        pred = predict(p, theta)\n",
    "    slop = (x_1 - x_2) / (y_1 - y_2)\n",
    "    return (intercept, slop)\n",
    "intercept, slop = get_intercept_slope(theta)\n",
    "\n",
    "def visualize(x, y, color, theta):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.scatter(x, y, c=color)\n",
    "    plt.plot(x, x * slop + intercept, 'b', linewidth=0.2)\n",
    "    plt.xlabel('Exam 1 score')\n",
    "    plt.ylabel('Exam 2 score')\n",
    "    plt.title('Figure 2: Training data with decision boundary')\n",
    "    plt.show()\n",
    "visualize(X[:,1], X[:,2], data.admission, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
